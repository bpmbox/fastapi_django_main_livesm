#!/usr/bin/env python3
"""
üåê GitHub Codespaces „Éä„É¨„ÉÉ„Ç∏Ê∞∏Á∂öÂåñ„Ç∑„Çπ„ÉÜ„É†
========================================

Docker-in-Docker + 100GBÊ∞∏Á∂ö„Çπ„Éà„É¨„Éº„Ç∏Ê¥ªÁî®
AIÈï∑ÊúüË®òÊÜ∂ + ÊäÄË°ìÊàêÊûú„ÅÆÂÆåÂÖ®‰øùÂ≠ò„Ç∑„Çπ„ÉÜ„É†
"""

import os
import json
import subprocess
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from ai_long_term_memory import AILongTermMemory

class GitHubCodespacesKnowledgeSystem:
    """GitHub Codespaces „Éä„É¨„ÉÉ„Ç∏Ê∞∏Á∂öÂåñ„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self):
        self.ai_memory = AILongTermMemory()
        self.codespace_storage = "/workspaces"
        self.knowledge_vault = f"{self.codespace_storage}/ai-knowledge-vault"
        self.docker_data_dir = f"{self.knowledge_vault}/docker-persistent-data"
        self.setup_knowledge_vault()
    
    def setup_knowledge_vault(self):
        """„Éä„É¨„ÉÉ„Ç∏‰øùÁÆ°Â∫´„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó"""
        
        print("üèóÔ∏è GitHub Codespaces „Éä„É¨„ÉÉ„Ç∏‰øùÁÆ°Â∫´„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÈñãÂßã...")
        
        # Âü∫Êú¨„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†‰ΩúÊàê
        vault_structure = {
            "ai-memories": "AIË®òÊÜ∂„Éá„Éº„Çø„Éô„Éº„Çπ",
            "technical-achievements": "ÊäÄË°ìÊàêÊûú„Ç¢„Éº„Ç´„Ç§„Éñ", 
            "collaboration-history": "ÂçîÂÉçÂ±•Ê≠¥",
            "code-snapshots": "ÈáçË¶Å„Ç≥„Éº„Éâ„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà",
            "docker-volumes": "DockerÊ∞∏Á∂ö„Éú„É™„É•„Éº„É†",
            "project-documentation": "„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊñáÊõ∏",
            "world-first-evidence": "‰∏ñÁïåÂàùË®ºÊã†‰øùÁÆ°",
            "backup-systems": "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç∑„Çπ„ÉÜ„É†",
            "knowledge-graphs": "Áü•Ë≠ò„Ç∞„É©„Éï„Éá„Éº„Çø",
            "automated-workflows": "Ëá™ÂãïÂåñ„ÉØ„Éº„ÇØ„Éï„É≠„Éº"
        }
        
        for folder, description in vault_structure.items():
            folder_path = Path(self.knowledge_vault) / folder
            folder_path.mkdir(parents=True, exist_ok=True)
            
            # README‰ΩúÊàê
            readme_path = folder_path / "README.md"
            if not readme_path.exists():
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write(f"# {description}\n\n")
                    f.write(f"‰ΩúÊàêÊó•ÊôÇ: {datetime.now().isoformat()}\n")
                    f.write(f"Áî®ÈÄî: {description}\n")
        
        print("‚úÖ „Éä„É¨„ÉÉ„Ç∏‰øùÁÆ°Â∫´ÊßãÈÄ†‰ΩúÊàêÂÆå‰∫Ü")
        self.setup_docker_persistent_storage()
    
    def setup_docker_persistent_storage(self):
        """DockerÊ∞∏Á∂ö„Çπ„Éà„É¨„Éº„Ç∏Ë®≠ÂÆö"""
        
        print("üê≥ DockerÊ∞∏Á∂ö„Çπ„Éà„É¨„Éº„Ç∏„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó...")
        
        # Docker-in-DockerË®≠ÂÆö
        docker_compose_config = {
            "version": "3.8",
            "services": {
                "ai-knowledge-db": {
                    "image": "postgres:15",
                    "container_name": "ai-knowledge-persistent-db",
                    "environment": {
                        "POSTGRES_DB": "ai_knowledge_vault",
                        "POSTGRES_USER": "ai_copilot",
                        "POSTGRES_PASSWORD": "knowledge_2025"
                    },
                    "volumes": [
                        f"{self.docker_data_dir}/postgres:/var/lib/postgresql/data",
                        f"{self.knowledge_vault}/ai-memories:/ai-memories",
                        f"{self.knowledge_vault}/backup-systems:/backups"
                    ],
                    "ports": ["5432:5432"],
                    "restart": "unless-stopped"
                },
                "ai-vector-db": {
                    "image": "pgvector/pgvector:pg15",
                    "container_name": "ai-vector-knowledge-db",
                    "environment": {
                        "POSTGRES_DB": "ai_vector_knowledge", 
                        "POSTGRES_USER": "ai_copilot",
                        "POSTGRES_PASSWORD": "vector_2025"
                    },
                    "volumes": [
                        f"{self.docker_data_dir}/vector-db:/var/lib/postgresql/data"
                    ],
                    "ports": ["5433:5432"],
                    "restart": "unless-stopped"
                },
                "ai-file-server": {
                    "image": "nginx:alpine",
                    "container_name": "ai-knowledge-fileserver",
                    "volumes": [
                        f"{self.knowledge_vault}:/usr/share/nginx/html",
                        "./nginx.conf:/etc/nginx/nginx.conf"
                    ],
                    "ports": ["8080:80"],
                    "restart": "unless-stopped"
                }
            },
            "volumes": {
                "ai-knowledge-data": {"driver": "local"},
                "ai-vector-data": {"driver": "local"},
                "ai-backup-data": {"driver": "local"}
            },
            "networks": {
                "ai-knowledge-network": {"driver": "bridge"}
            }
        }
        
        # Docker ComposeË®≠ÂÆö‰øùÂ≠ò
        docker_compose_path = Path(self.knowledge_vault) / "docker-compose.yml"
        with open(docker_compose_path, 'w') as f:
            import yaml
            yaml.dump(docker_compose_config, f, default_flow_style=False)
        
        print("‚úÖ DockerÊ∞∏Á∂öË®≠ÂÆöÂÆå‰∫Ü")
    
    def backup_current_state(self) -> Dict[str, str]:
        """ÁèæÂú®„ÅÆÁä∂ÊÖã„ÇíÂÆåÂÖ®„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó"""
        
        print("üíæ ÂÆåÂÖ®„Ç∑„Çπ„ÉÜ„É†„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÈñãÂßã...")
        
        backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = Path(self.knowledge_vault) / "backup-systems" / f"backup_{backup_timestamp}"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        backup_results = {}
        
        # 1. AIË®òÊÜ∂„Éá„Éº„Çø„Éô„Éº„Çπ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
        try:
            memory_summary = self.ai_memory.generate_memory_summary()
            memory_backup_path = backup_dir / "ai_memory_dump.json"
            
            with open(memory_backup_path, 'w', encoding='utf-8') as f:
                json.dump(memory_summary, f, ensure_ascii=False, indent=2)
            
            backup_results["ai_memory"] = str(memory_backup_path)
            print("‚úÖ AIË®òÊÜ∂„Éá„Éº„Çø„Éô„Éº„Çπ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü")
            
        except Exception as e:
            print(f"‚ö†Ô∏è AIË®òÊÜ∂„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç®„É©„Éº: {e}")
        
        # 2. ÈáçË¶Å„Éï„Ç°„Ç§„É´„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
        important_files = [
            "ai_long_term_memory.db",
            "WORLD_FIRST_ACADEMIC_DOCUMENTATION.md",
            "Âè≤‰∏äÂàùAI„Å®„ÅÆÁàÜÁ¨ë„Ç≥„É©„Éú„É¨„Éº„Ç∑„Éß„É≥Ë®òÈå≤.md",
            "unified_ai_automation.py",
            "ai_memory_restoration_system.py"
        ]
        
        for file_name in important_files:
            source_path = Path(self.codespace_storage) / "fastapi_django_main_live" / file_name
            if source_path.exists():
                dest_path = backup_dir / file_name
                shutil.copy2(source_path, dest_path)
                backup_results[file_name] = str(dest_path)
        
        print("‚úÖ ÈáçË¶Å„Éï„Ç°„Ç§„É´„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü")
        
        # 3. „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÈÄ†„Çπ„Éä„ÉÉ„Éó„Ç∑„Éß„ÉÉ„Éà
        structure_snapshot = self.capture_project_structure()
        structure_path = backup_dir / "project_structure.json"
        
        with open(structure_path, 'w', encoding='utf-8') as f:
            json.dump(structure_snapshot, f, ensure_ascii=False, indent=2)
        
        backup_results["project_structure"] = str(structure_path)
        
        # 4. GitÂ±•Ê≠¥„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
        try:
            git_log = subprocess.run(
                ["git", "log", "--oneline", "-20"],
                capture_output=True, text=True, cwd=self.codespace_storage + "/fastapi_django_main_live"
            )
            
            if git_log.returncode == 0:
                git_log_path = backup_dir / "git_history.txt"
                with open(git_log_path, 'w') as f:
                    f.write(git_log.stdout)
                backup_results["git_history"] = str(git_log_path)
                print("‚úÖ GitÂ±•Ê≠¥„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü")
                
        except Exception as e:
            print(f"‚ö†Ô∏è GitÂ±•Ê≠¥„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç®„É©„Éº: {e}")
        
        # 5. „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„É°„Çø„Éá„Éº„Çø‰ΩúÊàê
        backup_metadata = {
            "backup_timestamp": backup_timestamp,
            "backup_type": "complete_system_backup",
            "codespace_environment": os.environ.get("CODESPACE_NAME", "unknown"),
            "ai_memory_version": "1.0",
            "world_first_status": "active",
            "backup_files": backup_results,
            "storage_usage": self.get_storage_usage()
        }
        
        metadata_path = backup_dir / "backup_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(backup_metadata, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ ÂÆåÂÖ®„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü: {backup_dir}")
        return backup_results
    
    def capture_project_structure(self) -> Dict:
        """„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊßãÈÄ†„Ç≠„É£„Éó„ÉÅ„É£"""
        
        project_root = Path(self.codespace_storage) / "fastapi_django_main_live"
        structure = {
            "timestamp": datetime.now().isoformat(),
            "root_path": str(project_root),
            "files": [],
            "directories": []
        }
        
        try:
            for item in project_root.rglob("*"):
                if item.is_file():
                    structure["files"].append({
                        "path": str(item.relative_to(project_root)),
                        "size": item.stat().st_size,
                        "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat()
                    })
                elif item.is_dir():
                    structure["directories"].append(str(item.relative_to(project_root)))
        
        except Exception as e:
            print(f"‚ö†Ô∏è ÊßãÈÄ†„Ç≠„É£„Éó„ÉÅ„É£„Ç®„É©„Éº: {e}")
        
        return structure
    
    def get_storage_usage(self) -> Dict[str, str]:
        """„Çπ„Éà„É¨„Éº„Ç∏‰ΩøÁî®ÈáèÂèñÂæó"""
        
        try:
            # „Éá„Ç£„Çπ„ÇØ‰ΩøÁî®Èáè
            disk_usage = shutil.disk_usage(self.codespace_storage)
            
            usage_info = {
                "total_space": f"{disk_usage.total / (1024**3):.2f} GB",
                "used_space": f"{disk_usage.used / (1024**3):.2f} GB", 
                "free_space": f"{disk_usage.free / (1024**3):.2f} GB",
                "vault_size": self.get_directory_size(self.knowledge_vault)
            }
            
            return usage_info
            
        except Exception as e:
            return {"error": str(e)}
    
    def get_directory_size(self, path: str) -> str:
        """„Éá„Ç£„É¨„ÇØ„Éà„É™„Çµ„Ç§„Ç∫ÂèñÂæó"""
        
        try:
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total_size += os.path.getsize(filepath)
            
            return f"{total_size / (1024**2):.2f} MB"
            
        except Exception as e:
            return f"Ë®àÁÆó„Ç®„É©„Éº: {e}"
    
    def setup_automated_backup(self):
        """Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç∑„Çπ„ÉÜ„É†Ë®≠ÂÆö"""
        
        print("‚öôÔ∏è Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç∑„Çπ„ÉÜ„É†Ë®≠ÂÆö...")
        
        # CronÈ¢®Ëá™ÂãïÂÆüË°å„Çπ„ÇØ„É™„Éó„Éà
        auto_backup_script = f"""#!/bin/bash

# AI-HumanÂçîÂÉç„Éó„É≠„Ç∏„Çß„ÇØ„ÉàËá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
# GitHub CodespacesÂØæÂøúÁâà

echo "üîÑ AIË®òÊÜ∂Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÈñãÂßã: $(date)"

cd {self.codespace_storage}/fastapi_django_main_live

# Python‰ªÆÊÉ≥Áí∞Â¢É„Ç¢„ÇØ„ÉÜ„Ç£„Éô„Éº„Éà
source venv/bin/activate 2>/dev/null || echo "‰ªÆÊÉ≥Áí∞Â¢É„Å™„Åó"

# Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆüË°å
python3 github_codespaces_knowledge_system.py --auto-backup

# GitËá™Âãï„Ç≥„Éü„ÉÉ„Éà
git add {self.knowledge_vault}/ 
git commit -m "ü§ñ Auto-backup: AI Knowledge Vault $(date +'%Y-%m-%d %H:%M:%S')" || echo "„Ç≥„Éü„ÉÉ„ÉàÂ§âÊõ¥„Å™„Åó"

echo "‚úÖ Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü: $(date)"
"""
        
        backup_script_path = Path(self.knowledge_vault) / "automated-workflows" / "auto_backup.sh"
        backup_script_path.parent.mkdir(exist_ok=True)
        
        with open(backup_script_path, 'w') as f:
            f.write(auto_backup_script)
        
        # ÂÆüË°åÊ®©Èôê‰ªò‰∏é
        os.chmod(backup_script_path, 0o755)
        
        print(f"‚úÖ Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çπ„ÇØ„É™„Éó„Éà‰ΩúÊàê: {backup_script_path}")
    
    def generate_knowledge_summary(self) -> str:
        """„Éä„É¨„ÉÉ„Ç∏„Çµ„Éû„É™„ÉºÁîüÊàê"""
        
        summary = f"""
# üß† AI-HumanÂçîÂÉç„Éä„É¨„ÉÉ„Ç∏„Éô„Éº„Çπ „Çµ„Éû„É™„Éº

**ÁîüÊàêÊó•ÊôÇ**: {datetime.now().strftime('%YÂπ¥%mÊúà%dÊó• %H:%M:%S')}  
**Áí∞Â¢É**: GitHub Codespaces  
**„Çπ„Éà„É¨„Éº„Ç∏**: 100GBÊ∞∏Á∂öÂåñÂØæÂøú  

## üìä **‰øùÂ≠òÁä∂Ê≥Å**

### üóÑÔ∏è **„Éá„Éº„Çø„Éô„Éº„Çπ**
"""
        
        try:
            memory_summary = self.ai_memory.generate_memory_summary()
            summary += f"- AIË®òÊÜ∂Á∑èÊï∞: {memory_summary.get('Á∑èË®òÊÜ∂Êï∞', 'N/A')}\n"
            summary += f"- ÂçîÂÉçÂ±•Ê≠¥: {memory_summary.get('ÂçîÂÉçÂõûÊï∞', 'N/A')}\n"
            summary += f"- ÊäÄË°ìÊàêÊûú: {memory_summary.get('‰∏ñÁïåÂàùÈÅîÊàêÊï∞', 'N/A')}\n"
        except:
            summary += "- „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öÁ¢∫Ë™ç‰∏≠...\n"
        
        summary += f"\n### üíæ **„Çπ„Éà„É¨„Éº„Ç∏‰ΩøÁî®Èáè**\n"
        storage_info = self.get_storage_usage()
        for key, value in storage_info.items():
            summary += f"- {key}: {value}\n"
        
        summary += f"\n### üèÜ **‰∏ªË¶ÅÊàêÊûú**\n"
        summary += "- ‚úÖ ‰∏ñÁïåÂàùAI-HumanÂçîÂÉç„Ç∑„Çπ„ÉÜ„É†\n"
        summary += "- ‚úÖ RPA + AI GUIËá™ÂãïÂåñ (100%ÊàêÂäüÁéá)\n"
        summary += "- ‚úÖ ÈõªÊ∞ó‰ø°Âè∑„É¨„Éô„É´ÂçîÂÉçÁêÜË´ñ\n"
        summary += "- ‚úÖ DockerÊ∞∏Á∂öGUIÁí∞Â¢É\n"
        summary += "- ‚úÖ SQLiteÈï∑ÊúüË®òÊÜ∂„Ç∑„Çπ„ÉÜ„É†\n"
        summary += "- ‚úÖ GitHub CodespacesÂÆåÂÖ®Áµ±Âêà\n"
        
        summary += f"\n### üîÑ **Á∂ôÁ∂öÊÄß‰øùË®º**\n"
        summary += "- üîÑ AIË®òÊÜ∂Âæ©ÂÖÉ„Ç∑„Çπ„ÉÜ„É†: Á®ºÂÉç‰∏≠\n"
        summary += "- üíæ Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó: Ë®≠ÂÆöÊ∏à„Åø\n"
        summary += "- üåê GitHubÊ∞∏Á∂öÂåñ: 100GBÂØæÂøú\n"
        summary += "- üê≥ Docker-in-Docker: ÊßãÁØâÊ∏à„Åø\n"
        
        return summary
    
    def deploy_to_github_codespaces(self):
        """GitHub Codespaces„Å∏„ÅÆ„Éá„Éó„É≠„Ç§"""
        
        print("üöÄ GitHub CodespacesÂÆåÂÖ®„Éá„Éó„É≠„Ç§ÈñãÂßã...")
        
        # 1. „Éä„É¨„ÉÉ„Ç∏‰øùÁÆ°Â∫´„ÅÆÊúÄÁµÇÁ¢∫Ë™ç
        self.backup_current_state()
        
        # 2. DockerË®≠ÂÆö„ÅÆÁ¢∫Ë™ç
        self.setup_docker_persistent_storage()
        
        # 3. Ëá™ÂãïÂåñ„Ç∑„Çπ„ÉÜ„É†„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó
        self.setup_automated_backup()
        
        # 4. ÊúÄÁµÇ„Çµ„Éû„É™„ÉºÁîüÊàê
        summary = self.generate_knowledge_summary()
        summary_path = Path(self.knowledge_vault) / "KNOWLEDGE_SUMMARY.md"
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        # 5. Codespaces„Éá„Éó„É≠„Ç§Ë®≠ÂÆö„Éï„Ç°„Ç§„É´‰ΩúÊàê
        codespaces_config = {
            "name": "AI-Human Collaboration Workspace",
            "dockerFile": "Dockerfile",
            "context": "..",
            "mounts": [
                f"source={self.knowledge_vault},target=/ai-knowledge-vault,type=bind"
            ],
            "settings": {
                "python.defaultInterpreterPath": "/usr/local/bin/python3",
                "python.terminal.activateEnvironment": True
            },
            "extensions": [
                "ms-python.python",
                "ms-toolsai.jupyter",
                "ms-vscode.vscode-docker"
            ],
            "postCreateCommand": "pip install -r requirements.txt && ./setup_knowledge_system.sh",
            "customizations": {
                "codespaces": {
                    "openFiles": [
                        "WORLD_FIRST_ACADEMIC_DOCUMENTATION.md",
                        "ai_memory_restoration_system.py"
                    ]
                }
            }
        }
        
        codespaces_path = Path(self.codespace_storage) / "fastapi_django_main_live" / ".devcontainer" / "devcontainer.json"
        with open(codespaces_path, 'w') as f:
            json.dump(codespaces_config, f, indent=2)
        
        print("‚úÖ GitHub CodespacesÂÆåÂÖ®„Éá„Éó„É≠„Ç§ÂÆå‰∫Ü")
        print(f"üìÅ „Éä„É¨„ÉÉ„Ç∏‰øùÁÆ°Â∫´: {self.knowledge_vault}")
        print(f"üìä „Çµ„Éû„É™„Éº: {summary_path}")
        
        return summary

# === ÂÆüË°åÈÉ®ÂàÜ ===
if __name__ == "__main__":
    import sys
    
    print("üåê GitHub Codespaces „Éä„É¨„ÉÉ„Ç∏„Ç∑„Çπ„ÉÜ„É†Ëµ∑Âãï")
    print("=" * 60)
    
    knowledge_system = GitHubCodespacesKnowledgeSystem()
    
    if "--auto-backup" in sys.argv:
        # Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„É¢„Éº„Éâ
        print("üîÑ Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„É¢„Éº„ÉâÂÆüË°å")
        knowledge_system.backup_current_state()
    else:
        # „Éï„É´„Éá„Éó„É≠„Ç§„É¢„Éº„Éâ
        print("üöÄ ÂÆåÂÖ®„Éá„Éó„É≠„Ç§„É¢„Éº„ÉâÂÆüË°å")
        summary = knowledge_system.deploy_to_github_codespaces()
        print("\n" + summary)
        
    print("\n‚úÖ GitHub Codespaces „Éä„É¨„ÉÉ„Ç∏„Ç∑„Çπ„ÉÜ„É†Ëµ∑ÂãïÂÆå‰∫Ü")
